<!DOCTYPE html>
<html>
<head>
  <title>Continuously Improving Mobile Manipulation with Autonomous Real-World RL</title>

  <!-- <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet"> -->

  <!-- <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <link rel="icon" href="./favicon.ico?">



  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  <meta property="og:image:width" content="1600" />
  <meta property="og:image:height" content="900" />

</head>
<body>
  <section class="hero">
    <div class="hero-body no-bottom-padding">
      <div class="container">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Continuously Improving Mobile Manipulation with Autonomous Real-World RL</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a target="_blank" href="https://russellmendonca.github.io/">Russell Mendonca</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
                <a target="_blank" href="https://bucherb.github.io/">Bernadette Bucher</a><sup>2</sup>&nbsp;&nbsp;&nbsp;
                <a target="_blank" href="https://www.robo.guru/">Jiuguang Wang</a><sup>2</sup>&nbsp;&nbsp;&nbsp;
                <a target="_blank" href="https://www.cs.cmu.edu/~dpathak/">Deepak Pathak</a><sup>1</sup>
                <br /><sup>1</sup>Carnegie Mellon University&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<sup>2</sup>Boston Dynamics AI Institute
                <span class="brmod" ><b>In Submission</b></span>
              </span>
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="resources/paper.pdf"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a target="_blank" href="resources/main_vid.mp4"
                     class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                        <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>

              </div>
  
            </div>
            </div>
  
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>





  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <div align="center">
        <video id="teaser" muted playsinline controls autoplay loop width="100%">
          <source src="./resources/main_vid.mp4"
                  type="video/mp4">
        </video>
        
        <!-- <h2 class="title is-5">Input: observation<span style="opacity:0;"></span>Output: future prediction</h2> -->
        </div>  
        <br> 
        <h2 class="subtitle has-text-centered">
          Our approach learns skills directly in the real world via RL, without any demonstrations or simulation training.
        </h2>
  
      </div>
  
    </div>
  </section>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container is-two-thirds">
        <div class="columns is-centered has-text-centered">
          <div class="column is-two-thirds">
            <h2 class="title is-3">Abstract</h2>
          </div>
      </div>
    
      <div class="columns is-centered has-text-centered">
        <div class="column is-two-thirds ">
          <div class="content has-text-justified">
            To build generalist robots capable of executing a wide array of tasks across diverse environments, robots must be endowed with the ability to engage directly with the real world to acquire and refine skills without extensive instrumentation or human supervision. This work presents a fully autonomous real-world reinforcement learning framework for mobile manipulation that can both independently gather data and refine policies through accumulated experience in the real world. It has several key components: 
1) automated data collection strategies by guiding the robotâ€™s exploration toward object interactions, 
2) using goal cycles for world RL such that the robot changes goals once it has made sufficient progress, where the different goals serve as resets for one another, 
3) efficient control by leveraging basic task knowledge present in behavior priors in conjunction with policy learning and 
4) formulating generic rewards that combine human-interpretable semantic information with low-level, fine-grained state information. 
We demonstrate our approach on Boston Dynamics Spot robots in continually improving performance on a set of four challenging mobile manipulation tasks and show that this enables competent policy learning, obtaining an average success rate of 80\% across tasks, a 3-4 times improvement over existing approaches.
          </div>
        </div>
        </div>
      </div>
      </div>
    </div>
  </section>



  <section class="section" style="width: 100%; margin: 0 auto;">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h3 class="title is-3" style="text-align: center; padding-bottom: 5px;"><strong>Approach Overview</strong></h3>    
          <div class="columns is-centered">
            <div class="column is-three-quarters">
              <!-- <img src="resources/vrb_method.png" alt="VRB Model" style="border: 1px solid rgb(93, 92, 92); border-radius:10px; width: 100%;"> -->
              <img src="resources/method.png" alt="VRB Model" style="border: 1px; border-radius:10px; width: 100%;">
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-three-quarters has-text-centered">
              <div class="interpolation-panel">
                <div class="content">
                  <p style="font-size: 18px">
                  <b> Task-relevant Autonomy: </b>The robot needs to collect data with high signal to noise ratio, to learn more efficiently. We use an auto-grap procedure which uses segmentation models to identify objects of interest and grasp them before running the neural policy. Further we use goal cycles and/or multiple robots to automate resets for continual learning.  </p>
                </div>
              </div>
            </div>
          </div>

          <div class="columns is-centered">
            <div class="column is-three-quarters has-text-centered">
              <div class="interpolation-panel">
                <div class="content">
                  <p style="font-size: 18px">
                  <b> Efficient Control: </b> We combine a neural controller along with priors, which can take the form of planners with simplified models or simple scripts that generate suboptimal behavior. Neural policy learning is driven by model-free RL using Q learning by sampling data from both the online policy and prior.
                  </p>
                </div>
              </div>
            </div>
          </div>

          <div class="columns is-centered">
            <div class="column is-three-quarters has-text-centered">
              <div class="interpolation-panel">
                <div class="content">
                  <p style="font-size: 18px">
                  <b> Flexible Supervision: </b> We use language-guided detection models and vision segmentation models to identify objects of interest. We combine this with low-level depth observations for state estimation, which is used to specify rewards.</p>
                </div>
              </div>
            </div>
          </div>

        </div>
      </div>
    </div>
  </section>

  <section class="section" style="width: 100%; margin: 0 auto;">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h3 class="title is-3" style="text-align: center; padding-bottom: 5px;"><strong>Efficient continual improvement</strong></h3>    
          <div class="columns is-centered">
            <div class="column is-three-quarters">
              <!-- <img src="resources/vrb_method.png" alt="VRB Model" style="border: 1px solid rgb(93, 92, 92); border-radius:10px; width: 100%;"> -->
              <img src="resources/improvement.png"  style="border: 1px; border-radius:10px; width: 100%;">
            </div>
          </div>
          <div class="columns is-centered">
            <div class="column is-three-quarters has-text-centered">
              <div class="interpolation-panel">
                <div class="content">
                  <p style="font-size: 18px">
                  Our approach leverages both RL as well as a prior (such as a planner with a simplified model, or a simple script to generate behaviors). This learns much faster than vanilla RL, and reaches much better performance than just using the prior. Note that we use task-relevant autonomy procedures for all methods to make learning feasible.
                  </p>
                </div>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
  

  <section class="section">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-full-width">
          <h3 class="title is-3" style="text-align: center; padding-bottom: 10px;"> Exploration Learning Time-Lapse </h3>
          <tr>
           </tr>
          <tr>
            <td>
              <div class="content has-text-centered">
                <p style = "font-size: 20px">
                  We show the evolution of the robot's behavior as it practices and learns skills. These are learned over 8-10 hours practice in the real world.
         
                </p>
              </div>  
              <div class="row">
                <div class="col" >            
                    <video class="center" controls playsinline autoplay loop muted src="./resources/sweeping_timelapse.mp4" width="100%"
                           style="border-radius:10px; "></video>
                </div>
                <div class="col">
                  <video class="center" controls playsinline autoplay loop muted src="./resources/dustpan_pick_timelapse.mp4" width="100%"
                      style="border-radius:10px; "></video>
                  <!-- <img src="./resources/figures/strength.PNG" alt="Strength Results Table"  width="98%"> -->
                </div>
              </div>
  
              <br>
              
              <div class="row">
                <div class="col" >            
                    <video class="center" controls playsinline autoplay loop muted src="./resources/chairmove_tablemiddle_timelapse.mp4" width="100%"
                           style="border-radius:10px; "></video>
                </div>
                <div class="col">
                  <video class="center" controls playsinline autoplay loop muted src="./resources/chairmove_timelapse.mp4" width="100%"
                      style="border-radius:10px; "></video>
                  <!-- <img src="./resources/figures/strength.PNG" alt="Strength Results Table"  width="98%"> -->
                </div>
              </div>
                </div>
              </div>
            </td>
          </tr>
        </div> 
      </div>
    </div>
  </section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <br />
      <p> Template from <a href="https://nerfies.github.io"><span class="dnerf">Nerfies</span></a>.</p>
    </div>
  </div>
</footer>

</body>
</html>


